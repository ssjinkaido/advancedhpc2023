\documentclass[12pt]{article}
\renewcommand{\baselinestretch}{1.2}
\usepackage[utf8]{vietnam}
\usepackage[a4paper, total={6in, 8in}]{geometry}
\usepackage[english]{babel}
\usepackage{hyperref}
\usepackage{mathtools}
\usepackage{amssymb}
\usepackage{indentfirst}
\usepackage{graphicx}
\usepackage{minted}
\usepackage{ragged2e}
\usepackage{multirow}
\usepackage{subcaption}
\usepackage{xurl}
\usepackage{amsmath}
\usepackage{makecell}
\usepackage{algorithm}
\usepackage{algpseudocode}
\renewcommand\theadalign{bc}
\renewcommand\theadfont{\bfseries}
\renewcommand\theadgape{\Gape[4pt]}
\renewcommand\cellgape{\Gape[4pt]}
\usepackage{pbox}
\usepackage{graphicx}
\usepackage{diagbox}
\usepackage{listings}
\usepackage{xcolor}

\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    citecolor=blue,
    urlcolor=blue,
}
\lstset{
    backgroundcolor=\color{white},   
    basicstyle=\footnotesize,       
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    commentstyle=\color{red},    
    escapeinside={\%*}{*)},          
    extendedchars=true,              
    keepspaces=true,                 
    keywordstyle=\color{blue},       
    language=Python,                
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}
\begin{document}
\begin{center}
    \vspace*{1.8cm}
    \Large
    Labwork5\\
\end{center}

\noindent
First, we have an image:
\begin{figure}[H]
\centering
    \includegraphics[height = 0.5\textheight, keepaspectratio]{images/image.jpeg}
    \caption{A simple image}
\end{figure}

\noindent
First, we defined a function to blur an image without using shared memory

\begin{lstlisting}[language=Python]
@cuda.jit
def gaussian_convolution_without_sm(src, dst, gaussian_kernel):
    x, y = cuda.grid(2)

    if x < dst.shape[1] and y < dst.shape[0]:
        convolution_sum_r = 0.0
        convolution_sum_g = 0.0
        convolution_sum_b = 0.0
        for i in range(-3, 4):
            for j in range(-3, 4):
                x_pos = x + i
                y_pos = y + j
                if 0 <= x_pos < src.shape[1] and 0 <= y_pos < src.shape[0]:
                    convolution_sum_r += (
                        src[y_pos, x_pos, 0] * gaussian_kernel[i + 3, j + 3]
                    )
                    convolution_sum_g += (
                        src[y_pos, x_pos, 1] * gaussian_kernel[i + 3, j + 3]
                    )
                    convolution_sum_b += (
                        src[y_pos, x_pos, 2] * gaussian_kernel[i + 3, j + 3]
                    )

        dst[y, x, 0] = convolution_sum_r
        dst[y, x, 1] = convolution_sum_g
        dst[y, x, 2] = convolution_sum_b
\end{lstlisting}

\noindent
We have the resulting image:
\begin{figure}[H]
\centering
    \includegraphics[height = 0.5\textheight, keepaspectratio]{images/without_sm_blurred_image_gpu_(8, 8).png}
    \caption{Blurred image on GPU without using shared memory}
\end{figure}

\noindent
The time processed on GPU with different block sizes is:

\begin{lstlisting}[language=Python]
Block size: (8, 8), time processed: 0.29601597785949707
Block size: (16, 16), time processed: 0.0037779808044433594
Block size: (24, 24), time processed: 0.003228902816772461
Block size: (32, 32), time processed: 0.0036818981170654297
\end{lstlisting}

\noindent
We plot the time comparison between different block sizes. 

\begin{figure}[H]
\centering
    \includegraphics[width = \textwidth, keepaspectratio]{images/comparison_without_sm.png}
    \caption{Time comparison between different block sizes}
\end{figure}

\noindent
First, we defined a function to blur an image using shared memory

\begin{lstlisting}[language=Python]
@cuda.jit
def gaussian_convolution_with_sm(src, dst, gaussian_kernel):
    x, y = cuda.grid(2)
    shared_kernel = cuda.shared.array(shape=(7, 7), dtype=types.float32)
    if cuda.threadIdx.x < 7 and cuda.threadIdx.y < 7:
        shared_kernel[cuda.threadIdx.x, cuda.threadIdx.y] = gaussian_kernel[
            cuda.threadIdx.x, cuda.threadIdx.y
        ]

    cuda.syncthreads()
    if x < dst.shape[1] and y < dst.shape[0]:
        convolution_sum_r = 0.0
        convolution_sum_g = 0.0
        convolution_sum_b = 0.0
        for i in range(-3, 4):
            for j in range(-3, 4):
                x_pos = x + i
                y_pos = y + j
                if 0 <= x_pos < src.shape[1] and 0 <= y_pos < src.shape[0]:
                    convolution_sum_r += (
                        src[y_pos, x_pos, 0] * shared_kernel[i + 3, j + 3]
                    )
                    convolution_sum_g += (
                        src[y_pos, x_pos, 1] * shared_kernel[i + 3, j + 3]
                    )
                    convolution_sum_b += (
                        src[y_pos, x_pos, 2] * shared_kernel[i + 3, j + 3]
                    )

        dst[y, x, 0] = convolution_sum_r
        dst[y, x, 1] = convolution_sum_g
        dst[y, x, 2] = convolution_sum_b
\end{lstlisting}

\noindent
We have the resulting image:
\begin{figure}[H]
\centering
    \includegraphics[height = 0.5\textheight, keepaspectratio]{images/sm_blurred_image_gpu_(8, 8).png}
    \caption{Blurred image on GPU using shared memory}
\end{figure}

\noindent
The time processed on GPU with different block sizes is:

\begin{lstlisting}[language=Python]
Block size: (8, 8), time processed: 0.17975592613220215
Block size: (16, 16), time processed: 0.003142118453979492
Block size: (24, 24), time processed: 0.0031728744506835938
Block size: (32, 32), time processed: 0.0031371116638183594
\end{lstlisting}

\noindent
We plot the time comparison between different block sizes. 

\begin{figure}[H]
\centering
    \includegraphics[width = \textwidth, keepaspectratio]{images/comparison_sm.png}
    \caption{Time comparison between different block sizes}
\end{figure}


\noindent
Starting with a block size of (4, 4), the time processed is around 0.29-0.30 seconds without using shared memory. When we used shared memory, the time processed is around 0.17-0.18, which is already more than 1.6 times. We increased the block size by two and noticed that the code ran 1.2 times faster using shared memory. We further increased the block size and did not see a faster running time. 



\end{document}
